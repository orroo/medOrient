import requests

import faiss

from sentence_transformers import SentenceTransformer
import numpy as np
import pandas as pd



import httpx
import json
from openai import OpenAI
import re

from dotenv import load_dotenv

import os



load_dotenv()


EMBEDDING_MODEL_NAME=os.getenv("EMBEDDING_MODEL_NAME")

OCR_URL=os.getenv("OCR_URL")

ESPRIT_API_KEY=os.getenv("ESPRIT_API_KEY")

LLM_URL=os.getenv("LLM_URL")

# URL de ton API OCR

# Chemin de l'image Ã  envoyer

# # Ouvrir lâ€™image
# with open(image_path, "rb") as f:
#     files = {"image": (image_path, f, "image/jpeg")}
#     response = requests.post(url, files=files)

# # Affichage du rÃ©sultat
# print("Status:", response.status_code)
# print("RÃ©ponse OCR:", response.json())



# with open(image_path, "rb") as f:
#     data = {"image": (image_path, f, "/content/3.jpg")}
#     resp = requests.post(url, files=data)

# print(resp.json()["text"])
import re
import json
import httpx
from openai import OpenAI


def extract_text(path):
    with open(path, "rb") as f:
        data = {"image": (path, f, "/content/3.jpg")}
        resp = requests.post(OCR_URL, files=data)

    print(resp.json()["text"])
    return resp.json()["text"]



# --- Connexion Ã  lâ€™API TokenFactory --- 
# Utilisation de httpx pour la connexion HTTP avec TokenFactory (Llama)

# --- Connexion Ã  lâ€™API ESPRIT ---
http_client = httpx.Client(verify=False)
client = OpenAI(
    api_key=ESPRIT_API_KEY,
    base_url=LLM_URL,
    http_client=http_client
)


def correct_medicine_name_with_llama(med_name, dosage, duration):
    """
    Appelle llama pour valider ou corriger un nom de mÃ©dicament,
    en utilisant le dosage et la durÃ©e comme contexte pour plus de prÃ©cision.
    """
    # Utilisation de f-strings pour inclure les dÃ©tails contextuels
    prompt = f"""
    Vous Ãªtes un expert en pharmacie.

    VOTRE TÃ‚CHE UNIQUE :
    Corriger Ã©ventuellement le nom dâ€™un mÃ©dicament extrait dâ€™une ordonnance OCR.

    RÃˆGLES STRICTES (OBLIGATOIRES) :
    - RÃ©pondez avec UN SEUL nom de mÃ©dicament.
    - AUCUNE phrase.
    - AUCUNE explication.
    - AUCUNE ponctuation.
    - AUCUNE parenthÃ¨se.
    - AUCUNE alternative.
    - AUCUN commentaire.

    - Le nom fourni peut contenir des erreurs OCR.
    - La posologie et la durÃ©e servent UNIQUEMENT dâ€™indice contextuel lÃ©ger.
    - Si le nom est correct, retournez-le tel quel.
    - Si le nom est mal orthographiÃ©, proposez la correction la plus probable.
    - Si vous avez le moindre doute, retournez le nom original EXACTEMENT tel quâ€™il est fourni.
    - Ne remplacez JAMAIS un mÃ©dicament par un autre diffÃ©rent.
    - Ne dÃ©duisez JAMAIS une molÃ©cule Ã  partir du contexte.

    IMPORTANT :
    - If the input contains extra words or noise, focus ONLY on the drug name part.
    - If the cleaned name does not clearly match a known drug, return it unchanged.

    Informations de lâ€™ordonnance :
    - Nom extrait (OCR brut) : {med_name}
    - Posologie / Instructions : {dosage}
    - DurÃ©e : {duration}

    Nom du mÃ©dicament corrigÃ© ou confirmÃ© :

    """

    # Envoi de la requÃªte via l'API ESPRIT
    try:
        response = client.chat.completions.create(
            model="hosted_vllm/Llama-3.1-70B-Instruct",
            messages=[ 
                {"role": "system", "content": "Assistant mÃ©dical strict, factuel, sans spÃ©culation."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.4,
            max_tokens=700,
            top_p=0.9
        )

        # Log de la rÃ©ponse pour inspecter sa structure
        print("RÃ©ponse complÃ¨te de l'API:", response)

        # AccÃ©der Ã  la rÃ©ponse en extrayant les choix correctement
        content = response.choices[0].message.content  # Utiliser la bonne syntaxe pour accÃ©der au contenu
        return content

    except Exception as e:
        print(f"âš ï¸ Erreur lors de la correction du mÃ©dicament '{med_name}' : {e}")
        return {"drug": med_name, "error": str(e)}




def extract_and_correct_meds_with_llama(ocr_text):
    """
    Appelle llama pour extraire les mÃ©dicaments, la posologie et la durÃ©e
    d'un texte OCR. ConcentrÃ© sur l'extraction brute et le format JSON strict.
    """
    prompt = prompt = f"""
    Vous Ãªtes un systÃ¨me dâ€™extraction dâ€™informations Ã  partir dâ€™un texte OCR dâ€™ordonnance mÃ©dicale.

    VOTRE TÃ‚CHE UNIQUE :
    Extraire les mÃ©dicaments EXACTEMENT tels quâ€™ils apparaissent dans le texte OCR,
    ainsi que leur posologie et leur durÃ©e si prÃ©sentes.

    RÃˆGLES STRICTES :
    - Ne corrigez PAS lâ€™orthographe.
    - Ne devinez PAS le nom correct.
    - Ne choisissez PAS le mÃ©dicament â€œle plus probableâ€.
    - Ne normalisez RIEN.
    - Ne validez RIEN mÃ©dicalement.
    - Conservez les mots EXACTEMENT tels quâ€™ils apparaissent dans le texte OCR.

    - Le texte peut contenir des fautes OCR, des mots tronquÃ©s ou fusionnÃ©s.
    - Si une information est absente, utilisez "".

    FORMAT DE SORTIE OBLIGATOIRE :
    Vous devez rÃ©pondre UNIQUEMENT avec un JSON valide.
    AUCUN texte avant ou aprÃ¨s.
    AUCUNE explication.

    FORMAT EXACT :
    [
    {{
        "drug": "",
        "dosage": "",
        "duration": ""
    }}
    ]

    SI AUCUN MÃ‰DICAMENT Nâ€™EST TROUVÃ‰ :
    Retournez exactement []

    TEXTE OCR :
    {ocr_text}
    """
    # Envoi de la requÃªte via l'API ESPRIT
    try:
        response = client.chat.completions.create(
            model="hosted_vllm/Llama-3.1-70B-Instruct",
            messages=[ 
                {"role": "system", "content": "Assistant mÃ©dical strict, factuel, sans spÃ©culation."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.4,
            max_tokens=700,
            top_p=0.9
        )

        # Log de la rÃ©ponse pour inspecter sa structure
        print("RÃ©ponse complÃ¨te de l'API:", response)

        # AccÃ©der Ã  la rÃ©ponse en extrayant le contenu JSON depuis la rÃ©ponse de l'API
        response_text = response.choices[0].message.content  # Utiliser la bonne syntaxe pour accÃ©der au contenu
        print("RÃ©ponse textuelle extraite :", response_text)

        # VÃ©rifier si la rÃ©ponse est bien un JSON valide
        try:
            print(f"ğŸ” Response text type: {type(response_text)}")
            print(f"ğŸ” Response text length: {len(response_text) if response_text else 0}")
            print(f"ğŸ” Response text content: '{response_text}'")
            print(f"ğŸ” First 100 chars: '{response_text[:100] if response_text else 'EMPTY'}'")
            
            extracted_meds = json.loads(response_text)
        except json.JSONDecodeError as json_err:
            print(f"âš ï¸ Erreur lors du dÃ©codage JSON : {json_err}")
            print(f"âš ï¸ Contenu reÃ§u : {repr(response_text)}")
            return {"error": "RÃ©ponse API invalide", "details": str(response_text)}

        return extracted_meds

    except Exception as e:
        print(f"âš ï¸ Erreur lors de l'extraction et correction des mÃ©dicaments : {e}")
        return {"error": str(e)}






# # --- EXEMPLE D'UTILISATION ---
# ocr_text_input = "Rx Tab Auguentin 625mg x5day Enzoflarn 5days PaniD 40mg before meals Hexigel gum paste 1week"

# # Extrait et corrige les mÃ©dicaments extraits via Llama
# extracted_meds = extract_and_correct_meds_with_llama(ocr_text_input)

# # VÃ©rifier si la rÃ©ponse est bien un tableau de mÃ©dicaments
# if isinstance(extracted_meds, list):
#     # Correction supplÃ©mentaire avec Llama si nÃ©cessaire
#     corrected_meds = []
#     for item in extracted_meds:
#         corrected_name = correct_medicine_name_with_llama(item['drug'], item['dosage'], item['duration'])
#         corrected_meds.append({
#             "drug": corrected_name,
#             "dosage": item['dosage'],
#             "duration": item['duration']
#         })

#     # Afficher les rÃ©sultats
#     print("\n--- RÃ‰SULTAT FINAL ---")
#     print(json.dumps(corrected_meds, indent=2, ensure_ascii=False))
# else:
#     print(f"âš ï¸ Erreur : {extracted_meds.get('error', 'Erreur inconnue')}")






# ALWAYS CPU
try : 
    embedding_model = SentenceTransformer('models/'+EMBEDDING_MODEL_NAME)
    print( "loaded locally")
except :
    # If not found, load the model from the internet and save it locally
    embedding_model = SentenceTransformer( "sentence-transformers/"+EMBEDDING_MODEL_NAME
    )
    print("saving")
    embedding_model.save('models/'+EMBEDDING_MODEL_NAME)  # Save locally
    print("saved")

def compute_embeddings(text_list):
    embeddings = embedding_model.encode(text_list, convert_to_numpy=True, normalize_embeddings=True)
    return embeddings.astype("float32")





def create_faiss_index(embeddings):
    dim = embeddings.shape[1]
    index = faiss.IndexFlatIP(dim)  # cos similarity
    index.add(embeddings)
    return index



def match_drug_embeddings(drug_name, df, index, embeddings, threshold=0.80):

    query_emb = compute_embeddings([drug_name])  # (1, 384)

    scores, indices = index.search(query_emb, k=1)
    score = scores[0][0]
    idx = indices[0][0]

    if score >= threshold:
        return df["canonical"].iloc[idx], score

    return None, score





# # import pandas as pd
# df = pd.read_csv(r"C:\Users\hp\Desktop\4Ã¨me\projet\medicaments_clean_for_ocr.csv")

# # Compute dataset embeddings
# dataset_embeddings = compute_embeddings(df["canonical"].tolist())

# # Build index
# index = create_faiss_index(dataset_embeddings)

# # Query
# drug = "ENZOFLan"
# match, score = match_drug_embeddings(drug, df, index, dataset_embeddings)

# print(match, score)


# # --- Connexion API TokenFactory ---
# esprit_api_key = "sk-e376096028c847389e18f6d1f650be93"

# http_client = httpx.Client(verify=False)
# client = OpenAI(
#     api_key=esprit_api_key,
#     base_url="https://tokenfactory.esprit.tn/api",
#     http_client=http_client
# )


# ------------------------------------------------------
# ğŸ›¡ï¸ 1. JSON Cleaner : retire le markdown, rÃ©pare virgules
# ------------------------------------------------------
def clean_json_output(text):
    text = text.strip()

    # Enlever Ã©ventuels ```json ... ```
    text = re.sub(r"```json", "", text, flags=re.IGNORECASE).strip()
    text = re.sub(r"```", "", text).strip()

    # Retirer trailing commas avant les }
    text = re.sub(r",\s*}", "}", text)
    text = re.sub(r",\s*]", "]", text)

    return text


# ------------------------------------------------------
# ğŸ›¡ï¸ 2. VALIDATION DES CHAMPS
# ------------------------------------------------------
def validate_medical_card(card: dict, drug_name: str):
    """
    VÃ©rifie que la carte contient bien tous les champs requis.
    Corrige les types si nÃ©cessaire.
    """

    template = {
        "drug": drug_name,
        "class": "",
        "indications": [],
        "mechanism": "",
        "dosage": "",
        "side_effects": [],
        "contraindications": [],
        "interactions": []
    }

    for key, default in template.items():

        if key not in card:
            card[key] = default
            continue

        # Assurer les types corrects
        if isinstance(default, list) and not isinstance(card[key], list):
            card[key] = [card[key]] if card[key] else []

        if isinstance(default, str) and not isinstance(card[key], str):
            card[key] = str(card[key])

    return card


# ------------------------------------------------------
# ğŸ§  3. FONCTION PRINCIPALE : ULTRA-ROBUSTE
# ------------------------------------------------------
def generate_medical_card(drug: str):
    """
    GÃ©nÃ¨re une carte mÃ©dicale fiable, nettoyÃ©e et validÃ©e.
    """

    prompt = f"""
Tu es un expert mÃ©dical. Ta mission : gÃ©nÃ©rer UNE SEULE fiche mÃ©dicale fiable
pour le mÃ©dicament suivant : "{drug}".

RÃˆGLES STRICTES :
- Tu rÃ©ponds EXCLUSIVEMENT en JSON valide.
- Pas de texte avant ou aprÃ¨s le JSON.
- Remplis seulement ce que tu connais avec certitude.
- Si tu n'es pas sÃ»r, mets une chaÃ®ne vide "" ou une liste vide [].

FORMAT EXACT Ã€ RESPECTER :
{{
  "drug": "{drug}",
  "class": "",
  "indications": [],
  "mechanism": "",
  "dosage": "",
  "side_effects": [],
  "contraindications": [],
  "interactions": []
}}
"""

    try:
        response = client.chat.completions.create(
            model="hosted_vllm/Llama-3.1-70B-Instruct",
            messages=[
                {"role": "system", "content": "Assistant mÃ©dical strict, factuel, sans spÃ©culation."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.15,   # ğŸ”¥ plus basse â†’ moins d'hallucinations
            max_tokens=600
        )

        raw = response.choices[0].message.content.strip()

        # --- nettoyage JSON
        cleaned = clean_json_output(raw)

        try:
            parsed = json.loads(cleaned)
        except Exception:
            print("âš  JSON invalide. Sortie brute :")
            print(raw)
            return {"drug": drug, "error": "Invalid JSON", "raw": raw}

        # Validation-type + complÃ©tion des champs
        validated = validate_medical_card(parsed, drug)

        return validated

    except Exception as e:
        print(f"âš  Erreur gÃ©nÃ©ration carte mÃ©dicale pour {drug}: {e}")
        return {"drug": drug, "error": str(e)}
    




# card = generate_medical_card("Paracetamol")
# print(json.dumps(card, indent=2, ensure_ascii=False))















# import json

def add_drug_to_dataset(drug_name, medical_card, df, dataset_path):
    # Convert JSON â†’ string
    med_card_str = json.dumps(medical_card, ensure_ascii=False)

    new_row = {
        "canonical": drug_name,
        "med_card": med_card_str
    }

    df =  pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)  # âœ… Works 
    # df.append(new_row, ignore_index=True)

    # Save to disk
    df.to_csv(dataset_path, index=False, encoding="utf-8")

    return df


# HADI EL API mta3 el OCR + rag 

# # Charger dataset
# dataset_path = r"C:\Users\hp\Desktop\4Ã¨me\projet\medicaments_clean_for_ocr.csv"
# df = pd.read_csv(dataset_path)

# # VÃ©rifier si la colonne existe sinon la crÃ©er
# if "med_card" not in df.columns:
#     df["med_card"] = ""  # colonne vide
#     df.to_csv(dataset_path, index=False, encoding="utf-8")
#     print("ğŸ†• Colonne 'med_card' ajoutÃ©e au dataset.")
# else:
#     print("âœ” Colonne 'med_card' dÃ©jÃ  existante."





def process_drug(med, df, index, embeddings, dataset_path):

    # 1ï¸âƒ£ Correction LLM
    corrected_name = correct_medicine_name_with_llama(
        med["drug"], med["dosage"], med["duration"]
    )
    print(f"\nğŸ”§ Nom corrigÃ© : {corrected_name}")

    # 2ï¸âƒ£ Matching embedding sur NOM CORRIGÃ‰
    match, score = match_drug_embeddings(corrected_name, df, index, embeddings)

    # 3ï¸âƒ£ Si mÃ©dicament connu
    if match:
        print(f"âœ” Match trouvÃ© : {corrected_name} â†’ {match} (score={score:.2f})")

        row = df[df["canonical"] == match].iloc[0]
        raw_card = row["med_card"]

        # ---- CAS : Carte dÃ©jÃ  existante ----
        if isinstance(raw_card, str) and raw_card.strip() not in ["", "nan", "None"]:
            print(f"ğŸ“„ Carte mÃ©dicale trouvÃ©e pour {match}.")
            med_card = json.loads(raw_card)
            return match, med_card, df, index, embeddings

        # ---- CAS : Carte manquante â†’ gÃ©nÃ©rer nouvelle carte ----
        print(f"âš ï¸ Carte mÃ©dicale absente dans dataset pour {match}. GÃ©nÃ©ration en coursâ€¦")
        med_card = generate_medical_card(match)

        # Mise Ã  jour dataset
        df.loc[df["canonical"] == match, "med_card"] = json.dumps(med_card, ensure_ascii=False)
        df.to_csv(dataset_path, index=False, encoding="utf-8")

        return match, med_card, df, index, embeddings

    # 4ï¸âƒ£ Aucun match â†’ nouveau mÃ©dicament
    print(f"âŒ Aucun match pour {corrected_name} â†’ gÃ©nÃ©ration carte mÃ©dicaleâ€¦")
    med_card = generate_medical_card(corrected_name)

    # Ajout dans dataset
    new_row = {
        "canonical": corrected_name,
        "med_card": json.dumps(med_card, ensure_ascii=False)
    }
    
    df =  pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)  # âœ… Works
    # df.append(new_row, ignore_index=True)
    df.to_csv(dataset_path, index=False, encoding="utf-8")

    print(f"ğŸ†• MÃ©dicament ajoutÃ© au dataset : {corrected_name}")

    # Rebuild embeddings & FAISS
    embeddings = compute_embeddings(df["canonical"].tolist())
    index = create_faiss_index(embeddings)

    return corrected_name, med_card, df, index, embeddings



def pipeline(data_path,img_path):
    
    print("ğŸ“Œ Chargement du dataset...")
    df = pd.read_csv(data_path)

    # Ajouter colonne med_card si elle n'existe pas
    if "med_card" not in df.columns:
        df["med_card"] = ""
        df.to_csv(data_path, index=False, encoding="utf-8")
        print("ğŸ†• Colonne 'med_card' ajoutÃ©e.")

    print("ğŸ“Œ Calcul des embeddings...")
    embeddings = compute_embeddings(df["canonical"].tolist())

    print("ğŸ“Œ CrÃ©ation de l'index FAISS...")
    index = create_faiss_index(embeddings)


    ocr_text = extract_text(img_path)
    
    print("\nğŸ§ª OCR fourni :")
    print(ocr_text)


        
    extracted = extract_and_correct_meds_with_llama(ocr_text)

    print("\nğŸ” MÃ©dicaments extraits (brut OCR) :")
    print(json.dumps(extracted, indent=2, ensure_ascii=False))

    
    final_output = []

    for med in extracted:
        drug_name, med_card, df, index, embeddings = process_drug(
            med, df, index, embeddings, data_path
        )

        final_output.append({
            "drug": drug_name,
            "dosage": med["dosage"],
            "duration": med["duration"],
            "card": med_card
        })

        
    print("\n\nğŸ‰=== RÃ‰SULTAT FINAL DU PIPELINE ===ğŸ‰")
    print(json.dumps(final_output, indent=2, ensure_ascii=False))


    return final_output





# #######################################
# # ğŸ”¥ TEST COMPLET DU PIPELINE ğŸ”¥
# #######################################

# # Emplacement rÃ©el de ton dataset
# dataset_path = "C:/Users/hp/Desktop/4Ã¨me/projet/medicaments_clean_for_ocr.csv"

# print("ğŸ“Œ Chargement du dataset...")
# df = pd.read_csv(dataset_path)

# # Ajouter colonne med_card si elle n'existe pas
# if "med_card" not in df.columns:
#     df["med_card"] = ""
#     df.to_csv(dataset_path, index=False, encoding="utf-8")
#     print("ğŸ†• Colonne 'med_card' ajoutÃ©e.")

# print("ğŸ“Œ Calcul des embeddings...")
# embeddings = compute_embeddings(df["canonical"].tolist())

# print("ğŸ“Œ CrÃ©ation de l'index FAISS...")
# index = create_faiss_index(embeddings)


# ########################################
# # ğŸ” TEST OCR INPUT
# ########################################

# ocr_text = """
# Tab ENZOFLan 5mg x5day
# PaniD 40mg before meals
# Augmentin 1g x3day
# """

# print("\nğŸ§ª OCR fourni :")
# print(ocr_text)


# ########################################
# # ğŸ§ª EXTRACTION BRUTE
# ########################################

# extracted = extract_and_correct_meds_with_llama(ocr_text)

# print("\nğŸ” MÃ©dicaments extraits (brut OCR) :")
# print(json.dumps(extracted, indent=2, ensure_ascii=False))


# ########################################
# # ğŸ”¥ TRAITEMENT DE CHAQUE MÃ‰DICAMENT
# ########################################

# final_output = []

# for med in extracted:
#     drug_name, med_card, df, index, embeddings = process_drug(
#         med, df, index, embeddings, dataset_path
#     )

#     final_output.append({
#         "drug": drug_name,
#         "dosage": med["dosage"],
#         "duration": med["duration"],
#         "card": med_card
#     })


# ########################################
# # ğŸ‰ RESULTAT FINAL
# ########################################

# print("\n\nğŸ‰=== RÃ‰SULTAT FINAL DU PIPELINE ===ğŸ‰")
# print(json.dumps(final_output, indent=2, ensure_ascii=False))

# print("\nğŸ“Œ VÃ©rification : dataset mis Ã  jour â†’ OK")
# print("ğŸ“Œ Embeddings recalculÃ©s â†’ OK")
# print("ğŸ“Œ Index FAISS reconstruit â†’ OK")

# print("\nğŸ¯ TEST TERMINÃ‰ â€” TON PIPELINE FONCTIONNE âœ”")
